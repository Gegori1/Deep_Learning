{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8fb85e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Sección 1: Conceptos base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744efc8",
   "metadata": {
    "title": "1)"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ModelExample1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softamx = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.f1 = nn.Linear(13872, 100)\n",
    "        self.f2 = nn.Linear(100, 64)\n",
    "        self.f3 = nn.Linear(64, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.f1(x))\n",
    "        x = self.sigmoid(self.f2(x))\n",
    "        x = self.f3(x)\n",
    "        # softmax not implemented to \n",
    "        # implement cross entropy loss\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e49eb4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# a) crea un tensor con las siguientes dimensiones: (25, 3, 68, 68) e inicializalo con valores aleatorios entre 0.0 y 255.0  . \n",
    "\n",
    "X: torch.Tensor = torch.rand(25, 3, 68, 68) * 255.0\n",
    "X: torch.Tensor = X.to(device)\n",
    "\n",
    "# b) crea una instancia de tu red neuronal.\n",
    "model_example_1 = ModelExample1()\n",
    "\n",
    "# c) invoca la red neuronal con el tensor de entrada e imprime las dimensiones del tensor de salida.\n",
    "out = model_example_1(X)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c790d8",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "2)"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fit_t(\n",
    "        M, \n",
    "        X: torch.Tensor, \n",
    "        Y: torch.Tensor,\n",
    "        epochs: int, \n",
    "        batch_size: int, \n",
    "        loss, \n",
    "        optimizer, \n",
    "        checkpoint_path: str = None\n",
    "    ):\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    M.to(device) # move model to device\n",
    "    \n",
    "    # batch size it and shuffle\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    dataset = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for x, y in tqdm(dataset):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = M(x)\n",
    "            loss_ = loss(y_pred, y)\n",
    "            loss_.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss_.item())\n",
    "        \n",
    "        loss_history.append(np.mean(losses))\n",
    "        print(f\"Epoch {epoch} loss: {np.mean(losses)}\")\n",
    "        \n",
    "        if checkpoint_path is not None:\n",
    "        \n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": M.state_dict(),\n",
    "                    \"loss_history\": loss_history\n",
    "                },\n",
    "                checkpoint_path\n",
    "            )\n",
    "\n",
    "    return M, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf1ed4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# a) Definamos un tensor de entrada con las siguientes dimensiones: (777, 3, 68, 68). Con valores entre 0.0 y 1.0.\n",
    "X = torch.rand(777, 3, 68, 68)\n",
    "\n",
    "\n",
    "# b) Definamos un tensor de salida con las siguientes dimensiones: (777, 5)  y con valores entre 0 y 4 en una representación one hot vector.\n",
    "Y = torch.randint(0, 5, (777,))\n",
    "Y = nn.functional.one_hot(Y, num_classes=5).float()\n",
    "\n",
    "# c) Implementa una función u objeto iterable que te permita acceder a cada uno de los batch durante el ciclo de entrenamiento.\n",
    "\n",
    "# d) Crea una instancia del modelo que implementaste al iniciar la actividad (red neuronal para clasificación).\n",
    "model_example_2 = ModelExample1()\n",
    "\n",
    "# e) Utiliza la función fit_t() para entrenar la instancia del modelo con los datos sintéticos. Para inicializar el resto de los parámetros considera las características de los datos de entrada y salida, y que la tarea que se espera realice la red neuronal es una clasificación multiclase.\n",
    "optimizer = optim.Adam(model_example_2.parameters(), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "model_example_2, history = fit_t(\n",
    "    model_example_2,\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    checkpoint_path=\"model_example_2.pckl\"\n",
    ")\n",
    "\n",
    "# f) Al concluir el entrenamiento, no olvides verificar que los pesos y el loss total esten almacenados correctamente\n",
    "loaded_model = ModelExample1()\n",
    "state = torch.load(\"model_example_2.pckl\")\n",
    "loaded_model.load_state_dict(state[\"model_state_dict\"])\n",
    "\n",
    "loss_history = state[\"loss_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f04cc",
   "metadata": {
    "title": "3)"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fit_tv(\n",
    "        M, \n",
    "        dataset_train: torch.utils.data.TensorDataset,\n",
    "        dataset_val: torch.utils.data.TensorDataset,\n",
    "        epochs: int, \n",
    "        batch_size: int,\n",
    "        loss, \n",
    "        optimizer, \n",
    "        checkpoint_path: str = None\n",
    "    ):\n",
    "    \n",
    "    \n",
    "    dataset_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataset_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    loss_history_train, loss_history_eval = [], []\n",
    "    \n",
    "    M.to(device) # move model to device\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for x, y in tqdm(dataset_train):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = M(x)\n",
    "            loss_ = loss(y_pred, y)\n",
    "            loss_.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss_.item())\n",
    "        \n",
    "        loss_history_train.append(np.mean(losses))\n",
    "        print(f\"Epoch {epoch} loss: {np.mean(losses)}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            losses_eval = []\n",
    "            for x, y in tqdm(dataset_val):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = M(x)\n",
    "                loss_ = loss(y_pred, y)\n",
    "                losses_eval.append(loss_.item())\n",
    "                \n",
    "            loss_history_eval.append(np.mean(losses_eval))\n",
    "            \n",
    "        \n",
    "        if checkpoint_path is not None:\n",
    "        \n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": M.state_dict(),\n",
    "                    \"train_loss_history\": loss_history_train,\n",
    "                    \"validaation_loss_history\": loss_history_eval\n",
    "                },\n",
    "                checkpoint_path\n",
    "            )\n",
    "\n",
    "    return M, loss_history\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaff04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a) Definamos, \n",
    "\n",
    "# un tensor de entrada con las siguientes dimensiones: (1000, 3, 68, 68). Con valores entre 0.0 y 1.0.\n",
    "# un tensor de salida con las siguientes dimensiones: (1000, 5)  y con valores entre 0 y 4 en una representación one hot vector.\n",
    "# b) De los tensores anteriores utiliza el 80% para entrenamiento (X_train, Y_train) y el resto para validación (X_val, Y_val)\n",
    "X = torch.rand(1000, 3, 68, 68)\n",
    "Y = torch.randint(0, 5, (1000,))\n",
    "Y = nn.functional.one_hot(Y, num_classes=5).float()\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "dataset_size = X.shape[0]\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "\n",
    "dataset_train, dataset_val = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# c) Implementa una función u objeto iterable que te permita acceder a cada uno de los batch (datos de entrenamiento) durante el ciclo de entrenamiento.\n",
    "\n",
    "# d) Implementa una función u objeto iterable que te permita acceder a cada uno de los batch (datos de validación) durante el ciclo de validación.\n",
    "\n",
    "# e) Crea una instancia del modelo que implementaste al iniciar la actividad (red neuronal para clasificación).\n",
    "red_neuronal_para_clasificacion = ModelExample1()\n",
    "# f) Utiliza la función fit_tv() para entrenar y validar la instancia del modelo con los datos sintéticos. Para inicializar el resto de los parámetros considera las características de los datos de entrada y salida, y que la tarea que se espera realice la red neuronal es una clasificación multiclase.\n",
    "fit_tv(\n",
    "    red_neuronal_para_clasificacion,\n",
    "    dataset_train,\n",
    "    dataset_val,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    checkpoint_path=\"red_neuronal_para_clasificacion.pckl\"\n",
    "\n",
    ")\n",
    "# g) Al concluir el entrenamiento, no olvides verificar que los pesos, el loss total de entrenamiento y el loss total de validación esten almacenados correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e44b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
